[{"content":"","date":"15 November 2023","permalink":"/","section":"","summary":"","title":""},{"content":"","date":"15 November 2023","permalink":"/posts/","section":"","summary":"","title":""},{"content":"","date":"15 November 2023","permalink":"/posts/whoram/","section":"","summary":"","title":""},{"content":"","date":"15 November 2023","permalink":"/tags/first/","section":"Tags","summary":"","title":"first"},{"content":"","date":"15 November 2023","permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"RAM √© um hardware valioso e caro bem como a sua lat√™ncia √© ainda mais importante que a lat√™ncia do disco. E por isso, o kernel Linux tenta ao m√°ximo otimizar os uso da mem√≥ria, fazendo uso de t√©cnicas como compartilhando de p√°ginas entre processos e Page Cache para melhorar a velocidade de I/O de armazenamento, armazenando um subconjunto de dados do disco na mem√≥ria. O Page Cache realiza compartilhamento impl√≠cito de mem√≥ria e de forma ass√≠ncrona com o armazenamento em segundo plano! Isso por s√≠ s√≥, traz ainda mais complexidade √† estimativa de uso de mem√≥ria por parte dos administradores!\nMas o que √© Page Cache # o Page Cache faz parte do Virtual File System - VFS que √© uma camada de software do n√∫cleo que trata de todas as chamadas de sistema relacionadas a um sistema de arquivos Unix. Sua principal vantagem √© prover uma interface gen√©rica para diversos tipos de sistemas de arquivos. Ou seja, o VFS permite que chamadas de sistemas gen√©ricas, tais como open( ) e read( ),possam ser executadas independentemente do sistema de arquivos usados ou do meio f√≠sico! O que implica diretamente na lat√™ncia de I/O das opera√ß√µes de leitura e grava√ß√£o.\nQuando um sistema grava dados no cache, em algum momento ele tamb√©m deve gravar esses dados no armazenamento. O tempo dessa grava√ß√£o √© controlado pelo que √© conhecido como write policy, e existem duas abordagens b√°sicas de escrita:\nWrite-through: a grava√ß√£o √© feita de forma s√≠ncrona tanto no cache quanto no armazenamento de apoio. Write-back: inicialmente, a escrita √© feita apenas no cache. A grava√ß√£o no armazenamento de apoio √© adiada at√© que o conte√∫do modificado esteja prestes a ser substitu√≠do por outro bloco de cache. Nesse link voc√™ pode ter mais informa√ß√µes sobre o algor√≠timo Page √© a unidade de mem√≥ria que o Kernel trabalha com Page Cache, e geralmente possui 4k de comprimento m√≠nimo de armazenamento no Page Cache. Dessa forma todo I/O de arquivo est√° alinhado a uma quantidade espec√≠fica de p√°ginas\u0026hellip;\nAt√© aqui, podemos entender que o Page Cache, √© o principal cache de disco usado pelo kernel do Linux. Sendo utilizado ao ler ou gravar no disco; quando novas p√°ginas s√£o adicionadas ao cache de p√°ginas para satisfazer as solicita√ß√µes de leitura dos processos do Modo de Usu√°rio.\nSe a p√°gina ainda n√£o estiver no cache, uma nova entrada ser√° adicionada ao cache e preenchida com os dados lidos do disco. Se houver mem√≥ria livre suficiente, a p√°gina √© mantida no cache por um per√≠odo indefinido e pode ent√£o ser reutilizada por outros processos sem acessar o disco.\nDa mesma forma, antes de gravar uma p√°gina de dados em um dispositivo de bloco, o kernel verifica se a p√°gina correspondente j√° est√° inclu√≠da no cache; caso contr√°rio, uma nova entrada √© adicionada ao cache e preenchida com os dados a serem gravados no disco.\nA transfer√™ncia de dados de I/O n√£o come√ßa imediatamente: a atualiza√ß√£o do disco √© atrasada por alguns segundos, dando assim aos processos a chance de modificar ainda mais os dados a serem gravados (em outras palavras, o kernel implementa opera√ß√µes de deferred write). As p√°ginas inclu√≠das no Page Cache podem ser dos seguintes tipos:\nPages contendo dados de arquivos regulares; no Cap√≠tulo 16, descrevemos como o kernel lida com opera√ß√µes de leitura, grava√ß√£o e mapeamento de mem√≥ria neles. Pages contendo diret√≥rios; o Linux lida com os diret√≥rios de forma muito semelhante aos arquivos normais. Pages contendo dados lidos diretamente de arquivos de dispositivos de bloco (ignorando a camada do sistema de arquivos); o kernel os trata usando o mesmo conjunto de fun√ß√µes como para pages contendo dados de arquivos regulares. Pages contendo dados de processos do Modo Usu√°rio que foram trocados em disco; o kernel pode ser for√ßado a manter-se armazenado em page cache algumas pages cujo conte√∫do j√° foi escrito em uma √°rea de swap. Pages pertencentes a arquivos de sistemas de arquivos especiais, como o sistema de arquivos especial shm usado para regi√£o de mem√≥ria compartilhada de comunica√ß√£o entre processos (IPC). Como podemos ver, cada page inclu√≠da no Page Cache cont√©m dados pertencentes a algum arquivo. Este arquivo ‚Äì ou mais precisamente o inode do arquivo ‚Äì √© chamado de page‚Äôs owner.\nPraticamente todas as opera√ß√µes read() e write() de arquivos dependem do Page Cache.\na √∫nica exce√ß√£o ocorre quando um processo abre um arquivo com a flag O_DIRECT definido: neste caso, o cache da p√°gina √© ignorado e as transfer√™ncias de dados de E/S fazem uso de buffers no espa√ßo de endere√ßo do modo de usu√°rio do processo. V√°rias aplica√ß√µes database fazem uso da flag O_DIRECT pra que assim possam faze uso do pr√≥prio algor√≠timo de caching\u0026hellip; Os projetistas do kernel implementaram o Page Cache para atender a dois requisitos principais:\nLocalizar rapidamente um page espec√≠fica contendo dados relativos a um determinado propriet√°rio. Para aproveitar ao m√°ximo o cache da p√°gina, pesquis√°-lo deve ser uma opera√ß√£o muito r√°pida. Acompanhar como cada page do cache deve ser tratada ao ler ou escrever seu conte√∫do. Por exemplo, a leitura de uma page de um arquivo regular, ou de um arquivo de dispositivo de bloco ou de uma √°rea de swap, deve ser realizada de diferentes maneiras, portanto o kernel deve selecionar a opera√ß√£o adequada dependendo do propriet√°rio da p√°gina. A unidade de informa√ß√£o mantida no page cache √©, obviamente, uma p√°gina inteira de dados.\numa p√°gina n√£o cont√©m necessariamente blocos de disco fisicamente adjacentes, portanto ela n√£o pode ser identificada por um n√∫mero de dispositivo e um n√∫mero de bloco. Em vez disso, uma p√°gina no Page Cache √© identificada por um propriet√°rio e por um √≠ndice nos dados do propriet√°rio ‚Äì geralmente, um inode e um deslocamento dentro do arquivo correspondente. A estrutura de dados principal do cache de p√°gina √© o objeto address_space, uma estrutura de dados incorporada no objeto inode que possui a p√°gina.* Muitas p√°ginas no cache podem referir-se ao mesmo propriet√°rio, portanto, podem estar vinculadas ao mesmo objeto address_space. Este objeto tamb√©m estabelece uma liga√ß√£o entre as p√°ginas do propriet√°rio e um conjunto de m√©todos que operam nessas p√°ginas. Cada descritor de p√°gina inclui dois campos chamados mapeamento e √≠ndice, que vinculam a p√°gina ao cache de p√°ginas (consulte a se√ß√£o ‚ÄúDescritores de p√°ginas‚Äù no Cap√≠tulo 8). O primeiro campo aponta para o objeto address_space do inode que possui a p√°gina. O segundo campo especifica o deslocamento em unidades de tamanho de p√°gina dentro do ‚Äúespa√ßo de endere√ßo‚Äù do propriet√°rio, ou seja, a posi√ß√£o dos dados da p√°gina dentro da imagem de disco do propriet√°rio. Esses dois campos s√£o usados ao procurar uma p√°gina no cache de p√°ginas. Surpreendentemente, o cache de p√°ginas pode conter m√∫ltiplas c√≥pias dos mesmos dados do disco. Por exemplo, o mesmo bloco de dados de 4 KB de um arquivo normal pode ser acessado das seguintes maneiras: * Ocorre uma exce√ß√£o para p√°ginas que foram trocadas. Como veremos no Cap√≠tulo 17, essas p√°ginas possuem um objeto address_space comum n√£o inclu√≠do em nenhum inode. Este √© o t√≠tulo do livro, edi√ß√£o eMatter Copyright ¬© 2007 O‚ÄôReilly \u0026amp; Associates, Inc. Todos os direitos reservados. 602\nDessa forma vamos tentar algumas abordagens para determinar valores mais pr√≥ximos do real para o consumo de mem√≥ria RAM.\nRSS e VSZ # Vamos come√ßar tendo como referencia o VSZ que √© o tamanho da mem√≥ria virtual que o Linux concedeu a um processo. Mas n√£o necessariamente o processo est√° usando o valor informado. Um dos motivos s√£o programas com fun√ß√µes para realizar determinadas tarefas, mas s√≥ as carregam na RAM, quando necess√°rio. Bem como tamb√©m a pagina√ß√£o por demanda do Linux, que s√≥ carrega p√°ginas na mem√≥ria quando o aplicativo tenta us√°-las\u0026hellip; Por isso a leitura que devemos fazer do valor √©: mem√≥ria se carregadas todas as suas fun√ß√µes e bibliotecas na mem√≥ria f√≠sica.\nJ√° RSS, √© o tamanho do conjunto residente. √â a quantidade de RAM que o processo no momento para carregar as suas p√°ginas. Ainda assim n√£o podemos tomar essa informa√ß√£o como concreta, devido as bibliotecas compartilhadas torna-se um valor impreciso por superestimativa\u0026hellip;\nPrimeiro criamos um processo em um novo cgroup\nRodamos o comanod mtr utilizando o systemd-run para isol√°-lo num cgroup(por que sim\u0026hellip;rs) systemd-run --user -P -t -G --wait mtr 8.8.8.8 Em seguida coletamos o seu PID e verificamos os valores de RSS e VSZ\nCom o comando ps coletamos seu PID e os dados de RSS e VSZ O PID do processo $ ps -aux |grep -E systemd-run.*mtr | grep -v grep |awk \u0026#39;{print $2}\u0026#39; 236341 E os dados de RSS e VSZ $ ps -o rss,vsz,cmd -p $(ps -aux |grep -E systemd-run.*mtr | grep -v grep |awk \u0026#39;{print $2}\u0026#39;) RSS VSZ CMD 7168 14940 systemd-run --user -P -t -G --wait mtr 8.8.8.8 S√≥ a t√≠tulo de cuiriosidade, segue algumas formas de coverter o valor para megabytes: $ echo $((7168/1024)) 7 ou $ echo $((7168/1024)) |xargs -i printf \u0026#34;%\u0026#39;.1f MB\u0026#34; {} 7.0 MB ou $ numfmt --from=si --to=iec 7168K 6.9M ou $ numfmt --from=si --to-unit=1Mi --grouping 7168K 7 Podemos ver que o processo est√° consumindo 7168 Kilobytes.\nEm seguida usamos o procfs para ter mais detalhes desse uso de RAM que o RSS est√° apontando.\nVamos ver o arquivo smaps_rollup que √© uma soma das √°reas de mem√≥ria do smaps do nosso PID $ cat /proc/236341/smaps_rollup 559517c38000-7ffe5c398000 ---p 00000000 00:00 0 [rollup] Rss: 7368 kB Pss: 1171 kB Pss_Dirty: 868 kB Pss_Anon: 868 kB Pss_File: 303 kB Pss_Shmem: 0 kB Shared_Clean: 6444 kB Shared_Dirty: 0 kB Private_Clean: 56 kB Private_Dirty: 868 kB Referenced: 7368 kB Anonymous: 868 kB LazyFree: 0 kB AnonHugePages: 0 kB ShmemPmdMapped: 0 kB FilePmdMapped: 0 kB Shared_Hugetlb: 0 kB Private_Hugetlb: 0 kB Swap: 0 kB SwapPss: 0 kB Locked: 0 kB Para as m√©tricas listadas RSS que j√° √© nossa conhecida. PSS Proportional Set Size √© o compartilhamento proporcional de mem√≥ria do processo. √â a contagem de p√°ginas que ele possui na mem√≥ria, onde cada p√°gina √© dividida pelo n√∫mero de processos que a compartilham. Portanto, se um processo tiver 1.000 p√°ginas s√≥ para ele e 1.000 compartilhadas com outro processo, seu PSS ser√° 1.500. Shared_Clean aqui vemos que nosso processo usa cache de p√°gina. E representa o maior uso da mem√≥ria. No arquivo smaps, conseguimos ver todas as bibliotecas compartilhadas que foram abertas com mmap() e residem no Page Cache. Shared_Dirty quando o processo grava em arquivos com mmap(), esta linha mostra a quantidade de mem√≥ria suja do cache de p√°gina ainda n√£o salva. Referenced √© a quantidade de mem√≥ria referenciada ou acessada at√© o momento. O valor √© sempre igual ou pr√≥ximo RSS. Anonymous mostra a quantidade de mem√≥ria que n√£o pertence a nenhum arquivo. At√© qui podemos ver que, embora o comando PS e Top nos mostre um RSS de 7MiB, a maior parte de seu RSS est√° oculto no cache de p√°gina e que quando ficarem inativas por um tempo, essas p√°ginas, ser√£o removidas da RAM pelo kernel.\nNesse artigo do LWN.net temos mais informa√ß√µes direto da fonte ;).\nPMAP # O kernel Linux 2.6.32 deu ao Linux um recurso chamado ‚ÄúKernel SamePage Merging‚Äù. Isso significa que o Linux pode detectar regi√µes id√™nticas de dados em diferentes espa√ßos de endere√ßo. Imagine uma s√©rie de m√°quinas virtuais rodando em um √∫nico computador, e todas as m√°quinas virtuais rodando o mesmo sistema operacional. Usando um modelo de mem√≥ria compartilhada e c√≥pia na grava√ß√£o, a sobrecarga no computador host pode ser drasticamente reduzida.\nTudo isso torna sofisticado o manuseio de mem√≥ria no Linux. Mas √© dif√≠cil observar um processo e saber qual √© realmente o seu uso de mem√≥ria.\nO kernel exp√µe muito do que est√° fazendo com a RAM por meio de dois pseudoarquivos no pseudosistema de arquivos de informa√ß√µes do sistema ‚Äú/proc‚Äù. Existem dois arquivos por processo, nomeados de acordo com o ID do processo ou PID de cada processo:* ‚Äú/proc/$PID/maps‚Äù e ‚Äú/proc/$PID/smaps‚Äù.\nO valor [ anon ] √© o mapeamento de mem√≥ria an√¥nimo, que faz parte da mem√≥ria preenchida com dados n√£o retirados do sistema de arquivos, mas alocados quando necess√°rio.\nüññ\nAddress: The beginning memory address allocation\nKbytes: Memory allocation in kilobytes\nRSS: Resident set size of the process in memory\nDirty: The status of the memory pages\nMode: Access mode and privileges\nMapping: The user-facing name of the application or library\nOffset:\toffset into the file\nDevice:\tdevice name (major:minor)\nr: The mapped memory can be read by the process.\nw: The mapped memory can be written by the process.\nx: The process can execute any instructions contained in the mapped memory.\ns: The mapped memory is shared, and changes made to the shared memory are visible to all of the processes sharing the memory.\nR: There is no reservation for swap space for this mapped memory.\nAddress: The start address of this mapping. This uses virtual memory addressing.\nPerm: The permissions of the memory.\nOffset: If the memory is file-based, the offset of this mapping inside the file.\nDevice: The Linux device number, given in major and minor numbers. You can see the device numbers on your computer by running the lsblk command.\nInode: The inode of the file the mapping is associated with. For example, in our example, this could be the inode that holds information about the pm program.\nSize: The size of the memory-mapped region.\nKernelPageSize: The page size used by the kernel.\nMMUPageSize: The page size used by the memory management unit.\nRss: This is the resident set size. That is, the amount of memory that is currently in RAM, and not swapped out.\nPss: This is the proportional share size. This is the private shared size added to the (shared size divided by the number of shares.)\nShared_Clean: The amount of memory shared with other processes that has not been altered since the mapping was created. Note that even if memory is shareable, if it hasn\u0026rsquo;t actually been shared it is still considered private memory.\nShared_Dirty: The amount of memory shared with other processes that has been altered since the mapping was created.\nPrivate_Clean: The amount of private memory\u0026mdash;not shared with other processes\u0026mdash;that has not been altered since the mapping was created.\nPrivate_Dirty: The amount of private memory that has been altered since the mapping was created.\nReferenced: The amount of memory currently marked as referenced or accessed.\nAnonymous: Memory that does not have a device to swap out to. That is, it isn\u0026rsquo;t file-backed.\nLazyFree: Pages that have been flagged as MADV_FREE. These pages have been marked as available to be freed and reclaimed, even though they may have unwritten changes in them. However, if subsequent changes occur after the MADV_FREE has been set on the memory mapping, the MADV_FREE flag is removed and the pages will not be reclaimed until the changes are written.\nAnonHugePages: These are non-file backed \u0026ldquo;huge\u0026rdquo; memory pages (larger than 4 KB).\nShmemPmdMapped: Shared memory associated with huge pages. They may also be used by filesystems that reside entirely in memory.\nFilePmdMapped: The Page Middle Directory is one of the paging schemes available to the kernel. This is the number of file-backed pages pointed to by PMD entries.\nShared_Hugetlb: Translation Lookaside Tables, or TLBs, are memory caches used to optimize the time taken to access userspace memory locations. This figure is the amount of RAM used in TLBs that are associated with shared huge memory pages.\nPrivate_Hugetlb: This figure is the amount of RAM used in TLBs that are associated with private huge memory pages.\nSwap: The amount of swap being used.\nSwapPss: The swap proportional share size. This is the amount of swap made up of swapped private memory pages added to the (shared size divided by the number of shares.)\nLocked: Memory mappings can be locked to prevent the operating system from paging out heap or off-heap memory.\nTHPeligible: This is a flag indicating whether the mapping is eligible for allocating transparent huge pages. 1 means true, 0 means false. Transparent huge pages is a memory management system that reduces the overhead of TLB page lookups on computers with a large amount of RAM.\nVmFlags: See the list of flags below.\nMapping: The name of the source of the mapping. This can be a process name, library name, or system names such as stack or heap.\nThe VmFlags - will be a subset of the following list.\nrd: Readable. wr: Writeable. ex: Executable. sh: Shared. mr: May read. mw: May write. me: May execute. ms: May share. gd: Stack segment grows down. pf: Pure page frame number range. Page frame numbers are a list of the physical memory pages. dw: Disabled write to the mapped file. lo: Pages are locked in memory. io: Memory-mapped I/O area. sr: Sequential read advise provided (by the madvise() function.) rr: Random read advise provided. dc: Do not copy this memory region if the process is forked. de: Do not expand this memory region on remapping. ac: Area is accountable. nr: Swap space is not reserved for the area. ht: Area uses huge TLB pages. sf: Synchronous page fault. ar: Architecture-specific flag. wf: Wipe this memory region if the process is forked. dd: Do not include this memory region in core dumps. sd: Soft dirty flag. mm: Mixed map area. hg: Huge page advise flag. nh: No huge page advise flag. mg: Mergeable advise flag. bt: ARM64 bias temperature instability guarded page. mt: ARM64 Memory tagging extension tags are enabled. um: Userfaultfd missing tracking. uw: Userfaultfd wr-protect tracking. ","date":"15 November 2023","permalink":"/posts/whoram/whoram/","section":"","summary":"RAM √© um hardware valioso e caro bem como a sua lat√™ncia √© ainda mais importante que a lat√™ncia do disco.","title":"WhoRAM"},{"content":"","date":"6 November 2023","permalink":"/posts/dokawsrds/","section":"","summary":"","title":""},{"content":"","date":"6 November 2023","permalink":"/tags/aws/","section":"Tags","summary":"","title":"AWS"},{"content":"","date":"6 November 2023","permalink":"/tags/dok/","section":"Tags","summary":"","title":"DOK"},{"content":" IP DOK Set or Drop Sec Group AWS EC2 RDS # Fun√ß√£o # Scrip bash para descoberta de IPs de Droplets Nodes dos clusters Kubernetes e inser√ß√£o destes IPs, no security group EC2 das inst√¢ncias AWS RDS.\nDepend√™ncias # AWS CLI AWS CLI EC2 API authorize-security-group-ingress API describe-security-groups RDS API describe-db-instances DigitalOcean CLI DO CLI API compute Executando # Crie diret√≥rio tools em /usr/local\nmkdir -p /usr/local/tools/log \u0026amp;\u0026amp; cd /usr/local/tools/ \u0026amp;\u0026amp; \\ git clone git@github.com:0xttfx/ip-do_aws-rds.git \u0026amp;\u0026amp; cd ip-* N√£o h√° argumentos, bastando executar o .sh\n./script-0.3.sh Automa√ß√£o # Para automa√ß√£o da execu√ß√£o, adicione a seguinte linha na cron, para uma execu√ß√£o a cada 6 horas, ou modifique\u0026hellip; Devido ao update dos n√≥s dos clusters, que alteram os seus IPs, o script ser√° executado a cada 2 mintuos, afim de evitar indisponibilidade dos sistemas.\n*/2 * * * * user\t/usr/bin/bash -x /usr/local/tools/ip-do_aws-rds/script-0.3.sh \u0026gt;\u0026gt; /usr/local/tools/log/exec-script-0.3-$(date --date=\u0026#34;today\u0026#34; +\\%d\\%m\\%Y_\\%H\\%M).log 2\u0026gt;\u0026amp;1 0 0 * * * user\tfind /usr/local/tools/log -type f -mtime +3 -name \u0026#39;*.log\u0026#39; -exec rm {} + ","date":"6 November 2023","permalink":"/posts/dokawsrds/ip-dok-awsrds/","section":"","summary":"DigitalOcean Kubernetes and AWS RDS Security Group","title":"IP DOK Set or Drop Sec Group AWS EC2 RDS"},{"content":"","date":"6 November 2023","permalink":"/tags/rds/","section":"Tags","summary":"","title":"RDS"},{"content":"","date":"1 January 0001","permalink":"/authors/","section":"Authors","summary":"","title":"Authors"},{"content":"","date":"1 January 0001","permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":"1 January 0001","permalink":"/series/","section":"Series","summary":"","title":"Series"}]