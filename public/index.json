[{"content":"","date":"9 January 2024","permalink":"/","section":"","summary":"","title":""},{"content":"","date":"9 January 2024","permalink":"/posts/","section":"","summary":"","title":""},{"content":"","date":"9 January 2024","permalink":"/tags/first/","section":"Tags","summary":"","title":"first"},{"content":"Sempre existe a possibilidade de um dia aparecer um servidor com uma versão de SO não atual precisando que o NTP client seja configurado ou revisado… :)\nInstalando o serviço NTP\nInstale o pacote NTP com o utilitário yum $ yum install ntp -y Em seguida liste os comandos de administração fornecidos pelo pacote npt $ ntp\u0026lt;tab\u0026gt;\u0026lt;tab\u0026gt; ntpd ntpdate ntpdc ntp-keygen ntpq ntpstat ntptime Inicialize o serviço $ sudo service ntpd start ou $ sudo /etc/rc.d/init.d/ntpd start Ao iniciar o serviço, analise em seguida os logs no /var/log/messages $ sudo tail /var/log/messages ou $ grep ntpd /var/log/messages Jul 23 13:11:51 labcentos01 yum[9343]: Installed: ntpdate-4.2.4p83.el6.centos.x86_64 Jul 23 13:12:11 labcentos01 ntpd[9375]: ntpd Fri Feb 22 11:23:27 UTC 2013 (1) Jul 23 13:12:11 labcentos01 ntpd[9376]: precision = 0.111 usec Jul 23 13:12:11 labcentos01 ntpd[9376]: Listening on interface #0 wildcard... Jul 23 13:12:11 labcentos01 ntpd[9376]: Listening on interface #1 wildca... Jul 23 13:12:11 labcentos01 ntpd[9376]: Listening on interface #2 lo, ::1... Jul 23 13:12:11 labcentos01 ntpd[9376]: Listening on interface #3 eth0, .... Jul 23 13:12:11 labcentos01 ntpd[9376]: Listening on interface #4 lo, 127.0.... Automatize o serviço para que inicie no boot: $ sudo chkconfig --level 35 ntpd on Configuração do arquivo padrão do serviço “/etc/ntp.conf”\nSegue o arquivo padrão fornecido pelo pacote de instalação: # be tightened as well, but to do so would effect some of # the administrative functions. restrict 127.0.0.1 restrict -6 ::1 # Hosts on local network are less restricted. #restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap # Use public servers from the pool.ntp.org project. # Please consider joining the pool (http://www.pool.ntp.org/join.html). server 0.centos.pool.ntp.org iburst server 1.centos.pool.ntp.org iburst #broadcast 192.168.1.255 autokey # broadcast server #broadcastclient # broadcast client #broadcast 224.0.1.1 autokey # multicast server #multicastclient 224.0.1.1 # multicast client #manycastserver 239.255.254.254 # manycast server #manycastclient 239.255.254.254 autokey # manycast client # Enable public key cryptography. #crypto includefile /etc/ntp/crypto/pw # Key file containing the keys and key identifiers used when operating # with symmetric key cryptography. keys /etc/ntp/keys # Specify the key identifiers which are trusted. #trustedkey 4 8 42 # Specify the key identifier to use with the ntpdc utility. #requestkey 8 # Specify the key identifier to use with the ntpq utility. #controlkey 8 # Enable writing of statistics records. #statistics clockstats cryptostats loopstats peerstat Modifique as linhas “server”, substituindo pelo servidor NTP local; sendo uma linha para cada servidor\u0026hellip; : server 0.redhat.pool.ntp.org iburst server 1.redhat.pool.ntp.org iburst Modificando para o NTP Brasileiro ou na LAN: server 192.0.2.151 iburst ou server a.st1.ntp.br iburst ou server a.ntp.br iburst a flag iburst faz com que uma saraivada de mensagens sejam trocadas para preparar os dados e ajustar o relógio por cerca de 10s. Reinicie o serviço NTP sudo /etc/init.d/ntpd restart Agora visualize como ficou o arquivo de configuração do serviço NTP: $ sudo cat /etc/ntp.conf |grep -E -v \u0026#34;^$|^#\u0026#34; |nl 1 driftfile /var/lib/ntp/drift 2 restrict default kod nomodify notrap nopeer noquery 3 restrict -6 default kod nomodify notrap nopeer noquery 4 restrict 127.0.0.1 5 restrict -6 ::1 6 server 192.0.2.151 iburst 7 includefile /etc/ntp/crypto/pw 8 keys /etc/ntp/keys Outra opção interessante para habilitar no “ntp.conf” para a configuração cliente é a diretiva de estatísticas: # estatisticas do ntp que exibe informaões de funcionamento. statsdir /var/log/ntpstats/ statistics loopstats peerstats filegen loopstats file loopstats type day enable ilegen peerstats file peerstats type day enable Verificando se o daemon NTP está devidamente configurado e operando:\nExecute o comando “ntpq” com a opção “-c peers” que lista estatísticas dos servidores cadastrados no arquivo /etc/ntp.conf. $ sudo ntpq -c pe** ou $ sudo ntpq -c peers** se a resposta for algo parecido com a descrita abaixo, o daemon não está ativo localhost.localdomain: timed out, nothing received *****Request timed out** se a resposta for próxima da descrita abaixo, o NTP está operando: remote refid st t when poll reach delay offset jitter ========================================================================== *192.0.2.151 200.186.125.195 2 u 84 1024 377 0.750 0.138 0.279 Segue mais um resultado de um NTP com mais de 1 servidor de horas configurado remote refid st t when poll reach delay\toffset\tjitter ============================================================================= +a.st1.ntp.br .ONBR. 1 u 8 64\t1 11.929 -0.405\t1.353 201.49.148.135 .STEP. 16 u - 64 0 0.000 0.000 0.000 *d.st1.ntp.br .ONBR. 1 u 4 64 1 19.496 -0.530\t0.392 -a.ntp.br 200.160.7.186 2 u 4 64 1 11.061 0.117\t1.151 +b.ntp.br 200.20.186.76 2 u - 64 1 14.459 -2.561\t2.544 stratum 16 indica servidor inoperante. Compreendendo cada campo offset - mostra em milissegundos o quanto a hora no servidor precisa adiantar ou se atrasar para ficar igual a do servidor NTP ( esses valores devem estar em milissegundos! Acima de segundos não é um bom resultado.) delay mostra o tempo que o pacote demora para ir ao servidor e voltar para o host. jitter mostra o quanto em milissegundos existe de variação nas medidas de deslocamento dos pacotes e, o quanto mais baixo melhor. reach mostra o resultado em octal das últimas 8 tentativas de conexão ao servidor preferencial de horas. O valor esperado é “377” que indica que as últimas tentativas obtiveram sucesso! Valores diferentes indicam falhas ocorridas. Para melhor compreensão, é um registrador de 8 bits que vai girando para a esquerda representado na forma octal, que mostra o resultado das últimas 8 consultas à fonte de tempo: 377 = 11.111.111 significa que todas as consultas foram bem sucedidas; outros número indicam falhas, por exemplo 375 = 11.111.101, indica que a penúltima consulta falhou. refid mostra a referência (par do sistema) ao qual, o servidor de tempo remoto está sincronizado. st mostra o strato da fonte de tempo. when quanto segundos se passaram desde a última consulta à essa fonte de tempo. poll mostra de quantos em quantos segundos essa fonte é consultada. Execute-o novamente com a opção “-c rv” para visualizar o estado da hora local $ sudo ntpq -c rv assID=0 status=46f4 leap_add_sec, sync_ntp, 15 events, event_peer/strat_chg, version=\u0026#34;ntpd 4.2.4p8@1.1612-o Thu Jan 10 15:17:40 UTC 2013 (1)\u0026#34;, processor=\u0026#34;x86_64\u0026#34;, system=\u0026#34;Linux/2.6.32-279.19.1.el6.x86_64\u0026#34;, leap=01, stratum=3, precision=-24, rootdelay=15.668, rootdispersion=59.025, peer=14178, refid=192.0.2.151, reftime=d59b9d48.ef695513 Thu, Jul 25 2013 9:49:12.935, poll=10, clock=d59ba39e.61ba5ac8 Thu, Jul 25 2013 10:16:14.381, state=4, offset=0.073, frequency=7.577, jitter=0.051, noise=0.232, stability=0.018, tai=0 compreendendo os campos version mostra a versão do NTP e sua data e hora de construção. processor mostra a versão e plataforma do hardware. stratum que pode ir de 1 até 15 mostra a distância que o servidor NTP usado está do o relógio de referência que transmite a hora UCT, que por sua vez está em stratum-0! Lembrando que quanto mais próximo o servidor estiver do stratum-0, menos atraso ele terá em realação ao UCT; ou seja quanto menor a distância melhor\u0026hellip; Variável “peer” ID associado ao servidor NTP preferencial. reftime mostra a data e hora que o servidor preferencial foi atualizado pela última vez pelo seu stratum superior. clock data e hora do dia! Aquele que foi setado/configurado no seu servidor host. offset deslocamento, quanto o relógio local tem de ser adiantado ou atrasado para chegar à hora certa (horaigual à do estrato 0). precision precisão indicada com o expoente de um número base 2 Variável “rootdisperion” erro máximo da medida de offset em relação ao strato 0, em milissegundos. rootdelay atraso ou tempo de ida e volta dos pacotes atéo strato 0, em milissegundos. refid o par do sistema, ou principal referência. frequency erro na freqüência do relógio local, em relação à freqüência do estrato 0, em partes por milhão (PPM). Obtendo informações separadamente de cada servidor NTP configurado! Essa forma é utilizada por exemplo para medir as informações de um servidor NTP secundário afim de tomar alguma decisão como a de substituir o servidor preferencial problemático por algum outro do pool\u0026hellip; Primeiro liste o ID dos servidores NTP configurados com o comando “ntpq -c as”: $ sudo ntpq -c as ou sudo ntpq -c associations ind assID\tstatus conf\treach\tauth\tcondition\tlast_event\tcnt ===================================================================== 1 14178\t9614 yes\tyes none\tsys.peer\treachable\t1 Depois de obtido o ID obtenha as informações do servisor NTP entrando na linha de comando da ferramenta ntpq e utilize a opção “rv” seguido do ID. $ sudo ntpq [enter] $ sudo ntpq\u0026gt; rv 14178 assID=14178 status=9614 reach, conf, sel_sys.peer, 1 event, event_reach, srcadr=192.0.2.151, srcport=123, dstadr=192.0.2.140, dstport=123, leap=00, stratum=2, precision=-23, rootdelay=16.342,rootdispersion=16.281, refid=200.186.125.195, reach=377, unreach=0, hmode=3, pmode=4, hpoll=10, ppoll=10, flash=00 ok, keyid=0, ttl=0, offset=0.345, delay=1.032, dispersion=14.833, jitter=0.124, reftime=d59c0533.3051b8eb Thu, Jul 25 2013 17:12:35.188, org=d59c0552.e99941c5 Thu, Jul 25 2013 17:13:06.912, rec=d59c0552.e9a47a2b Thu, Jul 25 2013 17:13:06.912, xmt=d59c0552.e95ea055 Thu, Jul 25 2013 17:13:06.911, filtdelay= 1.03 1.12 1.22 1.10 0.64 1.30 1.57 1.09, filtoffset= 0.34 0.22 0.00 -0.01 0.16 -0.41 -0.41 -0.32, filtdisp= 0.00 15.38 30.75 46.11 61.50 76.85 92.22 107.58 Caso precise gerar alguma evidência para documentação, etc\u0026hellip; É possível gerar gráficos utilizando os logs de estatísticas do diretório “/var/log/ntpstats”, que são:\nloopstats, que apresenta as informações do loop local, ou seja, as variáveis do sistema. formato 54475 73467.286 -0.000057852 31.695 0.000015298 0.006470 4 54475 73548.286 -0.000084064 31.688 0.000017049 0.006471 4 54475 73682.286 -0.000077221 31.678 0.000016130 0.006988 4 54475 73698.286 -0.000077448 31.677 0.000015103 0.006550 4 54475 73761.286 -0.000083230 31.672 0.000014275 0.006376 4 54475 73889.286 -0.000059100 31.665 0.000015846 0.006487 4 54475 74004.285 -0.000045825 31.660 0.000015548 0.006324 4 - campos: - coluna 1: day - coluna 2: second - coluna 3: offset - coluna 4: drift compensation - coluna 5: estimed error - coluna 6: stability - coluna 7: polling interval peerstats que apresenta as informações de cada associação formato 54475 34931.294 200.20.186.75 9074 0.009958844 0.008390600 0.000390895 0.000132755 54475 34931.301 200.192.232.43 f0f4 0.000348814 0.015550265 0.001120348 0.000023645 54475 34932.303 200.189.40.28 f0f4 0.000810708 0.017701986 0.188995109 0.000043145 54475 34934.286 200.160.0.28 f0d4 0.000332344 0.000271801 0.000620139 0.000037467 54475 34935.286 200.160.7.165 9614 0.000003557 0.000216088 0.000826694 0.000022076 - campos - coluna 1: day - coluna 2: second - coluna 3: address - coluna 4: status - coluna 5: offset - coluna 6: delay - coluna 7: dispersion - coluna 8: skew/variance Além de poder ser usado para documentação, também fica mais fácil a leitura com o gráfico para ilustrá-lo. Excell pode ser usado\u0026hellip; Mas porque não usar terminal e gnuplot :). segue algumas referências: IBM Segue um exemplo de uso: Crie um arquivo texto com um nome pretendido, com o seguinte conteúdo: cat \u0026lt;\u0026lt;Fin\u0026gt; /tmp/deslocamento.txt set term gifset output \u0026#39;Deslocamento.png\u0026#39; set title \u0026#34;Deslocamento\u0026#34; plot \u0026#34;/var/log/ntpstats/loopstats\u0026#34; using 2:3 t\u0026#34;deslocamento\u0026#34; with linespoints lt rgb \u0026#34;#d82886\u0026#34;; Fin Estamos referenciando o arquivo loopstats e, fazendo uso das colunas 2 e 3! A coluna 2 indica o tempo, no dia, em segundos; e a coluna 3 indica o deslocamento, em milissegundos. Também estamos utilizando cores RGB declarada em hexadecimal. Agora geramos o gráfico $ gnuplot /tmp/deslocamento.txt ","date":"9 January 2024","permalink":"/posts/rtfmaleatoriedades-ntp/rtfmaleatoriedadesparasysadmin-oldntp/","section":"","summary":"Sempre existe a possibilidade de um dia aparecer um servidor com uma versão de SO não atual precisando que o NTP client seja configurado ou revisado… :)","title":"RTFMAleatoriedadesParaSysAdmin Old NTP Client"},{"content":"","date":"9 January 2024","permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":"6 January 2024","permalink":"/posts/rtfmaleatoriedades-ntcdocker/","section":"","summary":"","title":""},{"content":"O intuito desse how to é apoiar na solução de problemas rede de containers Docker\nDisclaimer # Se caiu aqui no momento em que está tentando apagar um incendio: você está no lugar errado!\nMas retorne depois do incendio .. ;) Requeriments # Para fazer um debug descente, precisamos estar familiarizados com questões básicas!\nComo as coisas \u0026ldquo;funfam\u0026rdquo; dabaixo do capô da containerização # Namespaces Linux fornecem as tecnologias fundamentais da implementação de containers. Fornecendo isolamento de recursos globais entre processos independentes\nNamespaces fornece isolamento e não restrição ao hardware adjacente! Isso é papel do cgroups São 8 namespaces até o momento\nMount - Mount points cria uma hierarquia de diretórios isolado do sistema de arquivos do host, visivel apenas pelo processo em execução nessa árvore de diretórios do namespace. UTS - Hostname and NIS domain name cria isolamento dos identificadores hostname e o NIS domain name que são definidos usando sethostname(2), setdomainname(2) e pode ser recuperado usando uname(2) , gethostname(2) e getdomainname(2) . IPC - System V IPC, POSIX message queues isolam sysvipc(7) - System V Objetos IPC e mq_overview(7) - POSIX filas de mensagens. Dessa forma, o namespace tem seus identificadores IPC e filas de mensageria POSIX próprios, vistos apenas pelos processos que executam nele. PID - Process IDs Cria espaço do número de ID do processo isolados do host. Permite que o processo containerizado faça uso do recurso bem legal, o Freezing of tasks que permite suspender um conjunto de processos de um contêiner e migralos para outro container, em outro host, enquanto os processos internos mantêm os mesmos PIDs\u0026hellip; agradeça ao Freezing tasks pelas mágicas no seu notebook ao hibernar\u0026hellip; Network - Network devices, stacks, ports, etc. fornecem isolamento dos dispositivos de rede, pilhas de protocolos IP v4 e v6, tabelas de roteamento IP, regras de firewall, os diretórios /proc/net (link para /proc/ pid /net ), /sys/class/net , arquivos em /proc/sys/net , soquetes etc\u0026hellip; Bem como também dos soquetes abstratos do domain unix(7). Tanto uma interface de rede física, quanto uma veth(4) User - User and group IDs Faz isolamento dos recursos credentials(7) que são os identificadores relacionados à segurança e atributos, em particular, IDs de usuário e IDs de grupo, o diretório raiz, keyrings(7) e capabilities(7). Cgroup - Cgroup root directory Faz o isolamento virtualizando a visão do cgroups(7) por um processo via /proc/pid/cgroup e /proc/pid/mountinfo. Dessa forma o namespace possui seu próprio conjunto de diretórios raiz cgroup, que são os caminhos relativos dos registros correspondentes no arquivo /proc/pid/cgroup, quando um processo cria um novo namespace usando clone(2) ou unshare(2) com a flag CLONE_NEWCGROUP\u0026hellip; Time - Boot and monotonic clocks O time afeta afeta várias APIs como o clock_gettime(2), clock_nanosleep(2), nanosleep(2), timer_settime(2), timerfd_settime(2) e /proc/uptime, fazendo a virtualização isolada dos relógios de sistema: CLOCK_MONOTONIC (e também CLOCK_MONOTONIC_COARSE e CLOCK_MONOTONIC_RAW ), um relógio não configurável que representa um tempo monótono desde então(conforme descrito por POSIX - \u0026ldquo;algun ponto não especificado no passado\u0026rdquo;). CLOCK_BOOTTIME (e também CLOCK_BOOTTIME_ALARM ), um relógio não configurável que é idêntico a CLOCK_MONOTONIC , exceto que também inclui qualquer momento em que o sistema está suspenso. Dessa forma já conseguimos tridimensionalizar mentalmente que:\nA coisa toda é meio que um processo containerizado por recursos que o fazem rodar em um diretório onde existirá um sistema de arquivos, fazendo com que o processo o veja como o uma arvore filesystem, com seus pid/gid e pilha de rede, hostname e domainname / nisdomainname bem como as chamadas IPC e relógios de sistema isolados do host hospedeiro.. Aqui vale lembrar que esses namespaces não são de propriedade do processo! Eles operam de forma independente qualquer outro processo pode ser containerizado nesses namespaces já existentes, dessa forma compatilhando-os\u0026hellip; E de forma independente pois você pode executar um processo dentro de um namespace Network, sem que ele tenha um Mount e UTS por exemplo isso é massa porque é possível usar um comando que existe no Host, porém a execução será dentro de um namespace! por isso, não é necessário instalar uma tool em um Mount de um processo containerizado para fazer teste ou debug\u0026hellip; O que nos interessa é o namespace Network! Por isso, apesar de eu explorar outros pontos, nesse nivelamento: network é o nosso foco\ncontinua\u0026hellip; # ","date":"6 January 2024","permalink":"/posts/rtfmaleatoriedades-ntcdocker/rtfmaleatoriedadesparasysadminsecopsdevopssnre-ntcdocker/","section":"","summary":"O intuito desse how to é apoiar na solução de problemas rede de containers Docker","title":"RTFM \u0026 Aleatoriedades Para SysAdmin, SecOps, DevOps,{S,N}RE - Network Trobleshooting Container Docker"},{"content":"","date":"6 January 2024","permalink":"/posts/rtfmaleatoriedades-swap/","section":"","summary":"","title":""},{"content":"Swapping foi introduzida como um backup em disco para páginas não mapeadas. E existem três tipos de páginas que devem ser tratadas pelo subsistema de swapping:\nPages que pertencem a uma região de memória anônima de um processo (User Mode stack) Dirty pages que pertencem a um mapeamento de memória privada de um processo Pages que pertencem a uma região de memória compartilhada IPC Numa \u0026ldquo;Regular Paging\u0026rdquo; cada entrada na \u0026ldquo;Page Table\u0026rdquo; inclui um sinalizador, uma \u0026ldquo;Present flag\u0026rdquo; e o Kernel explora esse sinalizador para sinalizar que uma página pertencente a um espaço de endereço de um processo qualquer foi \u0026ldquo;swapped out\u0026rdquo;! E além desse sinalizador, o Linux faz uso dos bits restantes do \u0026ldquo;Page Table\u0026rdquo; pra armazenar um identificador de \u0026ldquo;swapped-out page\u0026rdquo; que informa a localização no disco.\nA Principais características do subsistema swapping são:\nConfigura area swap para armazenamento de Pages que não possuem \u0026ldquo;disk image\u0026rdquo;. Gerencia espaço na área de swap alocando e liberando \u0026ldquo;page slots\u0026rdquo;. Fornece a função de \u0026ldquo;swap out\u0026rdquo; pages da RAM para a área de swap e \u0026ldquo;swap in\u0026rdquo; pages da área de swap para RAM. Faz uso da “swapped-out page identifiers” das entradas na \u0026ldquo;Page Table\u0026rdquo; que foram swapped para acompanhar as posições dos dados na área de swap. Em suma, o swapping é o principal recurso de \u0026ldquo;page frame reclaiming\u0026rdquo;! E se queremos ter certeza que todos os \u0026ldquo;page frames\u0026rdquo; obtidos por um processo, não apenas os \u0026ldquo;pages\u0026rdquo; que contem \u0026ldquo;disk image\u0026rdquo;, possam ser recuperados pelo PFRA, devemos fazer uso do swapping\u0026hellip;\nCom isso podemos deduzir que grandes áreas de swap dão poder ao Kernel para iniciar vários processos onde o total de solicitações de memória ultrapassa a quantidade de RAM física.\nE como na TI, nem tudo são flores, precisamos nos atentar que simular RAM em disco, nos traz um desempenho em milissegundos se comparado aos nanosegundos da RAM física ;)\n[!NOTE] Referencia: Daniel P. Bovet, Marco Cesati - Understanding the Linux Kernel - Capítulo 2 - Memory Addressing e Capítulo 17 - Page Frame Reclaiming\nAgora que nivelamos a introdução sobre swapping, vamos criar um espaço de troca, do tipo arquivo, que não muda em nada quando partição em disco: a não ser o processo de particionamento de disco etc\u0026hellip;\nVerificando se há algum swap sudo swapon --show Criando arquivo de swap de 2GiB sudo dd if=/dev/zero of=/swapfile count=2192 bs=1MiB Alterando permissão do arquivo sudo chmod 600 /swapfile Marcando o arquivo como um espaço de swap sudo mkswap /swapfile Verificando se está tudo ok sudo swapon --show Adicionando a linha no \u0026lsquo;/etc/fstab\u0026rsquo; para montagem automática echo \u0026#39;/swapfile none swap sw 0 0\u0026#39; | sudo tee -a /etc/fstab Ajustando a configuração de Swap O parâmetro /proc/sys/vmwappiness configura a frequência com que o sistema transfere dados da RAM para o espaço de swap. Sendo um valor entre 0 e 100 que representa uma porcentagem! Um valor baixo significa que o seu sistema Linux troca processos raramente enquanto um alto valor significa que os processos são gravados em disco imediatamente\nCom valores próximos de zero, o kernel não irá transferir dados para o disco a menos que seja absolutamente necessário. Lembre-se, as interações com o arquivo de swap são “dispendiosas”! Pois são mais lentas que as interações com a RAM. Valores que estão mais próximos de 100 irão tentar colocar mais dados no swap em um esforço para manter mais espaço da RAM livre. Dependendo do perfil de memória de seus aplicativos ou do motivo pelo qual você está usando o seu servidor, isso pode ser melhor em alguns casos. Swappiness: 60 Swap a partir de 40% de uso de RAM. Swappiness: 40 Swap a partir de 60% de uso de RAM. Swappiness: 20 Swap a partir de 80% de uso de RAM. Swappiness: 10. Swap a partir de 90% de uso de RAM. Swappiness: 1 Swap a partir de 99% de uso de RAM. Para um desktop, um valor de swappiness de 60 não é um valor ruim e normalmente é o valor dfault em uma distro Linux. Mas para um servidor, podemos deixá-lo mais próximo de 0, para fazer uso somente quando realmente necessário\nComo exemplo podemos setar para \u0026lsquo;10\u0026rsquo; para que o swap seja utilizado após 90% de RAM ocupada\nsudo sysctl vm.swappiness=10 Para garantir que esse valor irá se manter após um boot\necho \u0026#39;vm.swappiness=10\u0026#39; | sudo tee -a /etc/sysctl.conf Mas como sempre, não há uma receita de bolo! Em determinados cenários trocar processos de tempo de execução da RAM para o disco, deve ser evitado, noutros há vantagem\u0026hellip; Conhecer a aplicação irá lhe guiar na configuração mais apropriada!\nAjustando a confiuração do vfs_cache_pressure Esta opção controla a tendência do kernel de recuperar a memória que é usada para cache de diretórios e objetos inode.\nNo valor padrão de vfs_cache_pressure=100, o kernel tentará recuperar dentries e inodes a uma taxa \u0026ldquo;justa\u0026rdquo; em relação ao pagecache e à recuperação do swapcache. Diminuir vfs_cache_pressure faz com que o kernel prefira manter os caches dentry e inode. Quando vfs_cache_pressure=0, o kernel nunca recuperará dentries e inodes devido à pressão de memória e isso pode levar facilmente a condições de falta de memória. Aumentar vfs_cache_pressure além de 100 faz com que o kernel prefira recuperar dentries e inodes. Podemos definir isso em um valor mais conservador como 50\nsudo sysctl vm.vfs_cache_pressure=50 Vamos garantir que após um boot o valor permaneça\necho \u0026#39;vm.vfs_cache_pressure=50\u0026#39; | sudo tee -a /etc/sysctl.conf Agora sim! Vamos ativar o novo espaço de swapping sudo swapon /swapfile ","date":"6 January 2024","permalink":"/posts/rtfmaleatoriedades-swap/rtfmaleatoriedadesparasysadmin-swap/","section":"","summary":"Swapping foi introduzida como um backup em disco para páginas não mapeadas.","title":"RTFM \u0026 AleatoriedadesParaSysAdmin - Swap"},{"content":"","date":"5 January 2024","permalink":"/posts/rtfmaleatoriedades-journalctl/","section":"","summary":"","title":""},{"content":"Para quando a lei de Murphy exerce a sua força. É nessa hora, que do seu kit MacGyver, você tira o journalctl para identificar o que pode estar errado!\nDas muitas formas possíveis. Tem mais essa:\n$ journalctl --no-pager --since today --grep \u0026#39;fail|error|fatal\u0026#39; --output json|jq Com a opção \u0026ldquo;\u0026ndash;grep\u0026rdquo; filtramos palavras chave Com a opção \u0026ldquo;\u0026ndash;since\u0026rdquo; melhoramos nossa assertividade. Ex: \u0026ndash;since \u0026ldquo;1 hour ago\u0026rdquo; \u0026ndash;since \u0026ldquo;1 minutes ago\u0026rdquo; \u0026ndash;since \u0026ldquo;5 seconds ago\u0026rdquo; \u0026ndash;since 07:00 \u0026ndash;until \u0026ldquo;1 hour ago\u0026rdquo; Com o \u0026ldquo;\u0026ndash;output\u0026rdquo; usando o formato json, fazemos um parser amigável pra organizarmos com jq. $ journalctl --no-pager --since today --grep \u0026#39;fail|error|fatal\u0026#39; --output json|jq { \u0026#34;_PID\u0026#34;: \u0026#34;5605\u0026#34;, \u0026#34;_SYSTEMD_SLICE\u0026#34;: \u0026#34;user-1000.slice\u0026#34;, \u0026#34;_SYSTEMD_USER_UNIT\u0026#34;: \u0026#34;org.gnome.Shell@wayland.service\u0026#34;, \u0026#34;_RUNTIME_SCOPE\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;_SYSTEMD_UNIT\u0026#34;: \u0026#34;user@1000.service\u0026#34;, \u0026#34;__SEQNUM\u0026#34;: \u0026#34;7540847\u0026#34;, ... ... \u0026#34;_SYSTEMD_OWNER_UID\u0026#34;: \u0026#34;1000\u0026#34;, \u0026#34;SYSLOG_IDENTIFIER\u0026#34;: \u0026#34;google-chrome.desktop\u0026#34;, \u0026#34;_COMM\u0026#34;: \u0026#34;cat\u0026#34;, \u0026#34;__MONOTONIC_TIMESTAMP\u0026#34;: \u0026#34;285995139402\u0026#34;, \u0026#34;_CMDLINE\u0026#34;: \u0026#34;cat\u0026#34;, \u0026#34;_BOOT_ID\u0026#34;: \u0026#34;da45ccab9c404e9444444a9c51300cae\u0026#34;, \u0026#34;_EXE\u0026#34;: \u0026#34;/usr/bin/cat\u0026#34; } { ... ... Ainda é possível filtrar por algum objeto com o jq e quantificar as ocorrências com sort e uniq\nTalvez, alguns objetos interessantes seriam _EXE, _CMDLINE, _PID, SYSLOG_IDENTIFIER, MESSAGE\u0026hellip; $ journalctl --no-pager --since \u0026#34;60 minutes ago\u0026#34; --grep \u0026#39;fail|error|fatal\u0026#39; --output json|jq \u0026#39;.SYSLOG_IDENTIFIER\u0026#39; | sort | uniq -c 1 \u0026#34;audit\u0026#34; 1 \u0026#34;cupsd\u0026#34; 19 \u0026#34;discord.desktop\u0026#34; 2 \u0026#34;fprintd\u0026#34; 7 \u0026#34;gnome-shell\u0026#34; 10518 \u0026#34;google-chrome.desktop\u0026#34; 18 null 4 \u0026#34;org.gnome.Software.desktop\u0026#34; 173 \u0026#34;slack.desktop\u0026#34; ","date":"5 January 2024","permalink":"/posts/rtfmaleatoriedades-journalctl/rtfmaleatoriedadesparasysadmin-journalctl/","section":"","summary":"Para quando a lei de Murphy exerce a sua força.","title":"RTFM \u0026 Aleatoriedades para SysAdmin - journalctl "},{"content":"","date":"15 November 2023","permalink":"/posts/pagecache/","section":"","summary":"","title":""},{"content":"RAM é um hardware valioso e caro bem como a sua latência é ainda mais importante que a latência do disco. E por isso, o kernel Linux tenta ao máximo otimizar os uso da memória, fazendo uso de técnicas como compartilhando de páginas entre processos e Page Cache para melhorar a velocidade de I/O de armazenamento, armazenando um subconjunto de dados do disco na memória.\nO Page Cache realiza compartilhamento implícito de memória e de forma assíncrona com o armazenamento em segundo plano! Isso por sí só, traz ainda mais complexidade à estimativa de uso de memória por parte dos administradores!\nMas o que é Page Cache # o Page Cache faz parte do Virtual File System - VFS que é uma camada de software do núcleo que trata de todas as chamadas de sistema relacionadas a um sistema de arquivos Unix.\nSua principal vantagem é prover uma interface genérica para diversos tipos de sistemas de arquivos. Ou seja, o VFS permite que chamadas de sistemas genéricas, tais como open( ) e read( ),possam ser executadas independentemente do sistema de arquivos usados ou do meio físico! O que implica diretamente na latência de I/O das operações de leitura e gravação.\nQuando um sistema grava dados no cache, em algum momento também deve gravar esses dados no armazenamento. O tempo dessa gravação é controlado pelo que é conhecido como write policy, e existem duas abordagens básicas de escrita: Write-through: a gravação é feita de forma síncrona tanto no cache quanto no armazenamento de apoio.\nWrite-back: inicialmente, a escrita é feita apenas no cache. A gravação no armazenamento de apoio é adiada até que o conteúdo modificado esteja prestes a ser substituído por outro bloco de cache.\nNesse link você pode ter mais informações sobre o algorítimo Page é a unidade de memória que o Kernel trabalha com Page Cache, e geralmente possui 4k de comprimento mínimo de armazenamento no Page Cache.\nDessa forma todo I/O de arquivo está alinhado a uma quantidade específica de páginas\u0026hellip; Até aqui, podemos entender que o Page Cache, é o principal cache de disco usado pelo kernel do Linux e é utilizado ao ler ou gravar no disco quando novas páginas são adicionadas ao Page Cache para satisfazer as solicitações de leitura dos processos do User Mode stack.\nSe a página ainda não estiver no cache, uma nova entrada será adicionada ao cache e preenchida com os dados lidos do disco. Se houver memória livre suficiente, a página é mantida no cache por um período indefinido e pode então ser reutilizada por outros processos sem acessar o disco. Da mesma forma, antes de gravar page de dados em um dispositivo de bloco, o kernel verifica se a page correspondente já está incluída no cache; caso contrário, uma nova entrada é adicionada ao cache e preenchida com os dados a serem gravados no disco.\nA transferência de dados de I/O não começa imediatamente: - a atualização do disco é atrasada por alguns segundos, dando assim aos processos a chance de modificar ainda mais os dados a serem gravados em outras palavras, o kernel implementa operações de deferred write As páginas incluídas no Page Cache podem ser os seguintes tipos:\nPages contendo dados de arquivos regulares; no Capítulo 16, descrevemos como o kernel lida com operações de leitura, gravação e mapeamento de memória neles. Pages contendo diretórios; o Linux lida com os diretórios de forma muito semelhante aos arquivos normais. Pages contendo dados lidos diretamente de arquivos de dispositivos de bloco (ignorando a camada do sistema de arquivos); o kernel os trata usando o mesmo conjunto de funções como para pages contendo dados de arquivos regulares. Pages contendo dados de processos do User Mode stack que foram trocados em disco; o kernel pode forçar a manter-se armazenado em page cache algumas pages cujo conteúdo já foi escrito em uma área de swap. Pages pertencentes a arquivos de sistemas de arquivos especiais, como o sistema de arquivos especial shm usado para região de memória compartilhada de comunicação entre processos (IPC). Como podemos ver, cada page incluída no Page Cache contém dados pertencentes a algum arquivo. Este arquivo – ou mais precisamente o inode do arquivo – é chamado de page’s owner.\nPraticamente todas as operações read() e write() de arquivos dependem do Page Cache.\na única exceção ocorre quando um processo abre um arquivo com a flag O_DIRECT definido: neste caso, o cache da página é ignorado e as transferências de dados de E/S fazem uso de buffers no espaço de endereço do modo de usuário do processo. Várias aplicações database fazem uso da flag O_DIRECT pra que assim possam faze uso do próprio algorítimo de caching\u0026hellip; Os projetistas do kernel implementaram o Page Cache para atender a dois requisitos principais:\nLocalizar rapidamente um page específica contendo dados relativos a um determinado proprietário. Para aproveitar ao máximo o cache da página, pesquisá-lo deve ser uma operação muito rápida. Acompanhar como cada page do cache deve ser tratada ao ler ou escrever seu conteúdo. Por exemplo, a leitura de uma page de um arquivo regular, ou de um arquivo de dispositivo de bloco ou de uma área de swap, deve ser realizada de diferentes maneiras, portanto o kernel deve selecionar a operação adequada dependendo do proprietário da página. A unidade de informação mantida no page cache é, obviamente, uma página inteira de dados.\numa página não contém necessariamente blocos de disco fisicamente adjacentes, portanto ela não pode ser identificada por um número de dispositivo e um número de bloco. Em vez disso, uma página no Page Cache é identificada por um proprietário e por um índice nos dados do proprietário – geralmente, um inode e um offset dentro do arquivo correspondente. A estrutura de dados principal do Page Cache é o objeto address_space, uma estrutura de dados incorporada no objeto inode proprietário da page.\nMuitas pages no cache podem referir-se ao mesmo proprietário, portanto, podem estar vinculadas ao mesmo objeto address_space que também estabelece uma ligação entre a pages do proprietários e um conjunto de métodos que operam nessas pages. Aqui uma uma exceção ocorre para páginas que foram trocadas. Essas páginas possuem um objeto address_space comum não incluído em nenhum inode. Cada descritor de página inclui dois campos chamados mapping e index, que vinculam a page ao Page Cache\nO primeiro campo aponta para o objeto address_space do inode proprietário da page. O segundo campo especifica o offset em unidades de page-size dentro do addres_space! Ou seja: a posição dos dados da page dentro do disk image proprietário. Esses dois campos são usados ao procurar uma página no cache de páginas.\nMagitécnicamente, o cache de páginas pode conter múltiplas cópias dos mesmos dados do disco. Por exemplo, o mesmo bloco de dados de 4 KB de um arquivo normal pode ser acessado das seguintes maneiras:\nLendo o arquivo; os dados são incluídos em uma page pertencente ao inode do arquivo normal. Lendo o bloco do arquivo do dispositivo (partição do disco) que hospeda o arquivo; os dados são incluídos em uma page pertencente ao master inode do arquivo do dispositivo de bloco. Por isso, os dados de um disco aparecem em duas pages diferentes cada uma referenciada por um objeto address_space diferente\u0026hellip;\nAbaixo temos a tabela com os campos de um objeto adress_space\nType Field Description struct inode * host Pointer to the inode hosting this object, if any struct radix_tree_root page_tree Root of radix tree identifying the owner’s pages spinlock_t tree_lock Spin lock protecting the radix tree unsigned int i_mmap_writable Number of shared memory mappings in the address space struct prio_tree_root i_mmap Root of the radix priority search tree struct list_head i_mmap_nonlinear List of non-linear memory regions in the address space spinlock_t i_mmap_lock Spin lock protecting the radix priority search tree unsigned int truncate_count Sequence counter used when truncating the file unsigned long nrpages Total number of owner’s pages unsigned long writeback_index Page index of the last write-back operation on the owner’s pages struct address_space_ operations * a_ops Methods that operate on the owner’s pages unsigned long flags Error bits and memory allocator flag struct backing_dev_info * backing_dev_info Pointer to the backing_dev_info of the block device holding the data of this owner spinlock_t private_lock Usually, spin lock used when managing the private_list list struct list head private_list Usually, a list of dirty buffers of indirect blocks associated with the inode struct address_space * assoc_mapping Usually, pointer to the address_space object of the block device including the indirect blocks Se o owner de uma page no page cache for um arquivo, o objeto address_space será inserido no campo i_data de um objeto VFS inode.\nO campo i_mapping do inode sempre aponta para o objeto address_space do proprietário das pages que contêm os dados do inode. O campo host do objeto address_space aponta para o objeto inode no qual o descriptor está embutido\u0026hellip; Por isso, se uma page pertence a um arquivo armazenado em um sistema de arquivos Ext3,\no proprietário da page é o inode do arquivo e o objeto address_space correspondente é armazenado no campo i_data do objeto VFS inode. O campo i_mapping do inode aponta para o campo i_data do mesmo inode, e o campo host do objeto address_space aponta para o mesmo inode\u0026hellip; Mas como sempre: A \u0026ldquo;treta\u0026rdquo; está sempre presente na TI\u0026hellip; :)\nSe uma page contém dados, lidos de um arquivo de dispositivo de bloco(onde está o dado bruto(RAW)), o objeto address_space é incorporado no master inode do arquivo no sistema de arquivos especial bdev associado ao dispositivo de bloco.\nPor isso, o campo i_mapping de um inode de um arquivo de dispositivo de bloco, aponta para o objeto address_space embutido no master inode da mesma forma, o campo host do objeto address_space aponta também para o master idone dessa forma, todas as pages contendo dados lidos de um dispositivo de bloco possuem o mesmo objeto address_space, mesmo que tenham sido acessadas de arquivos de dispositivos de bloco diferentes Os campos i_mmap, i_mmap_writable, i_mmap_nonlinear e i_mmap_lock referem-se ao mapeamento de memória e ao mapeamento reverso.\nO campo backing_dev_info aponta o descritor backing_dev_info associado ao dispositivo de bloco que armazena os dados do proprietário.\na estrutura backing_dev_info geralmente é incorporada no descritor da fila de solicitações do dispositivo de bloco. O campo private_list é o cabeçalho de uma lista genérica que pode ser usada livremente pelo sistema de arquivos para seus propósitos específicos.\nO Ext2 faz uso desse campo coletar os buffers sujos de blocos “indiretos” associados ao inode. \u0026ldquo;buffers sujos\u0026rdquo; são dados ainda não escritos em disco. Quando uma operação força o inode a ser gravado em disco, o kernel também libera todos os buffers nesta lista. Um campo crucial do objeto address_space é a_ops.\nele aponta para uma tabela do tipo address_space_operations contendo os métodos que definem como as pages dos proprietários são tratadas. Os métodos mais importantes são: readpage writepage prepare_write commit_write Os métodos vinculam os proprietários do objetos inode aos drivers de baixo nível que acessam os dispositivos físicos.\nPor exemplo: a função que implementa o método readpage para um inode de um arquivo regular, sabe localizar as posições no dispositivo de disco físico dos blocos correspondentes a cada page do arquivo\u0026hellip; Abaixo podemos ver a tabela de métodos do address_space\nMethod Description writepage Write operation (from the page to the owner’s disk image) readpage Read operation (from the owner’s disk image to the page) sync_page Start the I/O data transfer of already scheduled operations on owner’s pages writepages Write back to disk a given number of dirty owner’s pages set_page_dirty Set an owner’s page as dirty readpages Read a list of owner’s pages from disk prepare_write Prepare a write operation (used by disk-based filesystems) commit_write Complete a write operation (used by disk-based filesystems) bmap Get a logical block number from a file block index invalidatepage Invalidate owner’s pages (used when truncating the file) releasepage Used by journaling filesystems to prepare the release of a page direct_IO Direct I/O transfer of the owner’s pages (bypassing the page cache) [!NOTE] Referencias: Daniel P. Bovet, Marco Cesati - Understanding the Linux Kernel, Third Edition-O\u0026rsquo;Reilly Media | Page Descriptors - Cap 8, Block Device Drivers - Cap 14 , The Page Cache - Cap 15, Accessing Files - Cap 16 , Page Frame Reclaiming - Cap 17 , The Ext2 and Ext3 Filesystems - Cap 18.\nAté aqui já conseguimos entender que o mecanismo de cachear arquivos em memória de forma transparente, independente de se estar mapeando algo em memória, lendo ou escrevendo em disco, deixam as coisas um pouco mais complicadas para um administrador inexperiente ao tentar obter uma aferição de consumo de memória\u0026hellip;\nPor isso, vamos tentar algumas abordagens para determinar valores mais próximos do real para o consumo de memória RAM.\nRSS e VSZ # Vamos começar tendo como referencia o VSZ que é o tamanho da memória virtual que o Linux concedeu a um processo. Mas não necessariamente o processo está usando o valor informado. Um dos motivos são programas com funções para realizar determinadas tarefas, mas só as carregam na RAM, quando necessário. Bem como também a paginação por demanda do Linux, que só carrega páginas na memória quando o aplicativo tenta usá-las\u0026hellip; Por isso a leitura que devemos fazer do valor é: memória se carregadas todas as suas funções e bibliotecas na memória física.\nJá RSS, é o tamanho do conjunto residente. É a quantidade de RAM que o processo no momento para carregar as suas páginas. Ainda assim não podemos tomar essa informação como concreta, devido as bibliotecas compartilhadas torna-se um valor impreciso por superestimativa\u0026hellip;\nPrimeiro criamos um processo em um novo cgroup\nRodamos o comanod mtr utilizando o systemd-run para isolá-lo num cgroup(por que sim\u0026hellip;rs) systemd-run --user -P -t -G --wait mtr 8.8.8.8 Em seguida coletamos o seu PID e verificamos os valores de RSS e VSZ\nCom o comando ps coletamos seu PID e os dados de RSS e VSZ O PID do processo $ ps -aux |grep -E systemd-run.*mtr | grep -v grep |awk \u0026#39;{print $2}\u0026#39; 236341 E os dados de RSS e VSZ $ ps -o rss,vsz,cmd -p $(ps -aux |grep -E systemd-run.*mtr | grep -v grep |awk \u0026#39;{print $2}\u0026#39;) RSS VSZ CMD 7168 14940 systemd-run --user -P -t -G --wait mtr 8.8.8.8 Só a título de cuiriosidade, segue algumas formas de coverter o valor para megabytes: $ echo $((7168/1024)) 7 ou $ echo $((7168/1024)) |xargs -i printf \u0026#34;%\u0026#39;.1f MB\u0026#34; {} 7.0 MB ou $ numfmt --from=si --to=iec 7168K 6.9M ou $ numfmt --from=si --to-unit=1Mi --grouping 7168K 7 Podemos ver que o processo está consumindo 7168 Kilobytes.\nEm seguida usamos o procfs para ter mais detalhes desse uso de RAM que o RSS está apontando.\nVamos ver o arquivo smaps_rollup que é uma soma das áreas de memória do smaps do nosso PID $ cat /proc/236341/smaps_rollup 559517c38000-7ffe5c398000 ---p 00000000 00:00 0 [rollup] Rss: 7368 kB Pss: 1171 kB Pss_Dirty: 868 kB Pss_Anon: 868 kB Pss_File: 303 kB Pss_Shmem: 0 kB Shared_Clean: 6444 kB Shared_Dirty: 0 kB Private_Clean: 56 kB Private_Dirty: 868 kB Referenced: 7368 kB Anonymous: 868 kB LazyFree: 0 kB AnonHugePages: 0 kB ShmemPmdMapped: 0 kB FilePmdMapped: 0 kB Shared_Hugetlb: 0 kB Private_Hugetlb: 0 kB Swap: 0 kB SwapPss: 0 kB Locked: 0 kB Para as métricas listadas RSS que já é nossa conhecida. PSS Proportional Set Size é o compartilhamento proporcional de memória do processo. É a contagem de páginas que ele possui na memória, onde cada página é dividida pelo número de processos que a compartilham. Portanto, se um processo tiver 1.000 páginas só para ele e 1.000 compartilhadas com outro processo, seu PSS será 1.500. Shared_Clean aqui vemos que nosso processo usa cache de página. E representa o maior uso da memória. No arquivo smaps, conseguimos ver todas as bibliotecas compartilhadas que foram abertas com mmap() e residem no Page Cache. Shared_Dirty quando o processo grava em arquivos com mmap(), esta linha mostra a quantidade de memória suja do cache de página ainda não salva. Referenced é a quantidade de memória referenciada ou acessada até o momento. O valor é sempre igual ou próximo RSS. Anonymous mostra a quantidade de memória que não pertence a nenhum arquivo. Até qui podemos ver que, embora o comando PS e Top nos mostre um RSS de 7MiB, a maior parte de seu RSS está oculto no cache de página e que quando ficarem inativas por um tempo, essas páginas, serão removidas da RAM pelo kernel.\nNesse artigo do LWN.net temos mais informações direto da fonte ;).\nContinua em breve\u0026hellip; # ","date":"15 November 2023","permalink":"/posts/pagecache/pagecache/","section":"","summary":"RAM é um hardware valioso e caro bem como a sua latência é ainda mais importante que a latência do disco.","title":"Who Page Cache"},{"content":"","date":"6 November 2023","permalink":"/posts/dokawsrds/","section":"","summary":"","title":""},{"content":"","date":"6 November 2023","permalink":"/tags/aws/","section":"Tags","summary":"","title":"AWS"},{"content":"","date":"6 November 2023","permalink":"/tags/dok/","section":"Tags","summary":"","title":"DOK"},{"content":" IP DOK Set or Drop Sec Group AWS EC2 RDS # Função # Scrip bash para descoberta de IPs de Droplets Nodes dos clusters Kubernetes e inserção destes IPs, no security group EC2 das instâncias AWS RDS.\nAtualizações # 0.4v Como inteválo mínimo de execução na CRON são de 60 segundos! E eu precisava executar por mais vezes por minuto acabei contendo o scrip dentro de um laço wile que o executa por 10 vezes com intervalo de 2 segundos 0.5v removido laço de execução a cada 60s restruturado algumas conditional statement da inserção e remoção de IPs O diff, antes realizado globalmente, agora é realizado para cada Security Group Dependências # AWS CLI\nAWS CLI EC2 API authorize-security-group-ingress API describe-security-groups RDS API describe-db-instances DigitalOcean CLI\nDO CLI API compute Repositório script\nip-do_aws-rds.sh Executando # Crie diretório tools e tools/log em /usr/local\nmkdir -p /usr/local/tools/log \u0026amp;\u0026amp; cd /usr/local/tools/ \u0026amp;\u0026amp; \\ git clone git@github.com:0xttfx/ip-do_aws-rds.git \u0026amp;\u0026amp; cd ip-* Não há argumentos, bastando executar o .sh\n./script-0.5.sh Automação # Para automação da execução, adicione a seguinte linha na cron Devido ao update dos nós dos clusters, que alteram os seus IPs, o script será executado a cada 1 mintuo!\naltere conforme sua necessidade. * * * * * user\t/usr/bin/bash -x /usr/local/tools/ip-do_aws-rds/script-0.5.sh \u0026gt;\u0026gt; /usr/local/tools/log/exec-script-0.5-$(date --date=\u0026#34;today\u0026#34; +\\%d\\%m\\%Y_\\%H\\%M\\%S).log 2\u0026gt;\u0026amp;1 0 0 * * * user\tfind /usr/local/tools/log/ -type f -mtime +3 -name \u0026#39;exec-*.log\u0026#39; -exec rm {} + ","date":"6 November 2023","permalink":"/posts/dokawsrds/ip-dok-awsrds/","section":"","summary":"DigitalOcean Kubernetes and AWS RDS Security Group","title":"IP DOK Set or Drop Sec Group AWS EC2 RDS"},{"content":"","date":"6 November 2023","permalink":"/tags/rds/","section":"Tags","summary":"","title":"RDS"},{"content":"","date":"1 January 0001","permalink":"/authors/","section":"Authors","summary":"","title":"Authors"},{"content":"","date":"1 January 0001","permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":"1 January 0001","permalink":"/series/","section":"Series","summary":"","title":"Series"}]